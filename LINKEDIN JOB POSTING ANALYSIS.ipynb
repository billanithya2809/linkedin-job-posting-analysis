{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install 'numpy<2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.24.4 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Import libraries\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# 📁 Load data\n",
    "companies = pd.read_csv(\"companies.csv\")\n",
    "company_industries = pd.read_csv(\"company_industries.csv\")\n",
    "industries = pd.read_csv(\"industries.csv\")\n",
    "job_skills = pd.read_csv(\"job_skills.csv\")\n",
    "skills = pd.read_csv(\"skills.csv\")\n",
    "salaries = pd.read_csv(\"salaries.csv\")\n",
    "employee_counts = pd.read_csv(\"employee_counts.csv\")\n",
    "\n",
    "# 🔍 Let's check the columns to avoid merge errors\n",
    "print(\"company_industries columns:\", company_industries.columns)\n",
    "print(\"industries columns:\", industries.columns)\n",
    "\n",
    "# 1️⃣ Top 10 Industries by Number of Companies\n",
    "# company_industries uses 'industry' (name), not 'industry_id'\n",
    "top_industries = company_industries['industry'].value_counts().head(10).reset_index()\n",
    "top_industries.columns = ['Industry', 'Company Count']\n",
    "\n",
    "fig1 = px.bar(top_industries, x='Industry', y='Company Count',\n",
    "              title=\"Top 10 Industries by Number of Companies\",\n",
    "              text='Company Count', color='Company Count')\n",
    "fig1.update_layout(xaxis_tickangle=-45)\n",
    "fig1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2️⃣ Top 10 In-Demand Skills\n",
    "skills_df = job_skills.merge(skills, on=\"skill_abr\", how=\"left\")\n",
    "top_skills = skills_df['skill_name'].value_counts().head(10).reset_index()\n",
    "top_skills.columns = ['Skill', 'Job Count']\n",
    "\n",
    "fig2 = px.bar(top_skills, x='Skill', y='Job Count',\n",
    "              title=\"Top 10 In-Demand Skills in Job Postings\",\n",
    "              text='Job Count', color='Job Count')\n",
    "fig2.update_layout(xaxis_tickangle=-45)\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3️⃣ Median Salary by Pay Period\n",
    "salaries_cleaned = salaries.dropna(subset=[\"med_salary\"])\n",
    "median_salary = salaries_cleaned.groupby(\"pay_period\")[\"med_salary\"].median().reset_index()\n",
    "\n",
    "fig3 = px.bar(median_salary, x=\"pay_period\", y=\"med_salary\",\n",
    "              title=\"Median Salary by Pay Period\",\n",
    "              text=\"med_salary\", color=\"med_salary\")\n",
    "fig3.update_layout(xaxis_title=\"Pay Period\", yaxis_title=\"Median Salary (USD)\")\n",
    "fig3.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4️⃣ Employee Count vs Follower Count\n",
    "fig4 = px.scatter(employee_counts,\n",
    "                  x=\"employee_count\", y=\"follower_count\",\n",
    "                  title=\"Employee Count vs Follower Count\",\n",
    "                  labels={\"employee_count\": \"Employee Count\", \"follower_count\": \"Follower Count\"},\n",
    "                  size=\"employee_count\", color=\"follower_count\")\n",
    "fig4.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load postings (has both job_id and company_id)\n",
    "postings = pd.read_csv(\"postings.csv\")\n",
    "\n",
    "# Merge salary with postings to get company_id\n",
    "salaries_with_company = postings[['job_id', 'company_id']].merge(\n",
    "    salaries[['job_id', 'med_salary']],\n",
    "    on='job_id', how='inner'\n",
    ")\n",
    "\n",
    "# Merge with company info to get company size\n",
    "company_salary_df = salaries_with_company.merge(\n",
    "    companies[['company_id', 'company_size']],\n",
    "    on='company_id', how='left'\n",
    ")\n",
    "\n",
    "# Drop missing values if any\n",
    "company_salary_df = company_salary_df.dropna(subset=['company_size', 'med_salary'])\n",
    "\n",
    "# Plot with Plotly\n",
    "fig5 = px.box(company_salary_df, x='company_size', y='med_salary',\n",
    "              title=\"Salary Distribution by Company Size\",\n",
    "              labels={\"company_size\": \"Company Size\", \"med_salary\": \"Median Salary\"})\n",
    "fig5.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "postings_df = pd.read_csv(\"postings.csv\")\n",
    "\n",
    "# Filter to only US jobs and non-null states\n",
    "us_jobs = postings_df[(postings_df['location'].str.contains('United States|USA|US|U.S.', na=False)) | (postings_df['location'].str.contains(', [A-Z]{2}', na=False))]\n",
    "us_jobs = us_jobs[~us_jobs['location'].isna()]\n",
    "\n",
    "# Extract state abbreviation from location string (e.g., \"Princeton, NJ\")\n",
    "us_jobs['state'] = us_jobs['location'].str.extract(r',\\s*([A-Z]{2})')\n",
    "\n",
    "# Group by state and count job listings\n",
    "state_counts = us_jobs['state'].value_counts().reset_index()\n",
    "state_counts.columns = ['state', 'job_count']\n",
    "\n",
    "# Plot US State Choropleth\n",
    "fig1 = px.choropleth(\n",
    "    state_counts,\n",
    "    locations='state',\n",
    "    locationmode=\"USA-states\",\n",
    "    color='job_count',\n",
    "    scope=\"usa\",\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    title=\"📍 Jobs Distribution by State in the United States\"\n",
    ")\n",
    "fig1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls for all 3 geographic levels\n",
    "geo_df = postings_df.dropna(subset=['location'])\n",
    "\n",
    "# Try extracting city/state/country (basic assumption parsing location string)\n",
    "# This will only work properly if you had explicit city/state/country columns; here we infer:\n",
    "geo_df[['city', 'state']] = geo_df['location'].str.extract(r'^([^,]+),\\s*([A-Z]{2})')\n",
    "geo_df['country'] = 'United States'  # Optional: defaulting for demo if most data is US-based\n",
    "\n",
    "# Group by location hierarchy\n",
    "grouped_geo = geo_df.groupby(['country', 'state', 'city']).size().reset_index(name='job_count')\n",
    "\n",
    "# Sunburst Chart\n",
    "fig2 = px.sunburst(\n",
    "    grouped_geo,\n",
    "    path=['country', 'state', 'city'],\n",
    "    values='job_count',\n",
    "    title=\"🌐 Global Job Opportunities Sunburst: From Country to City\",\n",
    "    height=600\n",
    ")\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV files\n",
    "job_skills = pd.read_csv(\"job_skills.csv\")\n",
    "skills = pd.read_csv(\"skills.csv\")\n",
    "\n",
    "# Merge using 'skill_abr' (not 'skill_id')\n",
    "merged = job_skills.merge(skills, on=\"skill_abr\", how=\"left\")\n",
    "\n",
    "# Count skills and get top 10\n",
    "skill_counts = merged['skill_abr'].value_counts()\n",
    "top_skills = skill_counts[:10]\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 5))\n",
    "top_skills.plot(kind=\"bar\", color='skyblue', edgecolor='black')\n",
    "plt.title(\"Top 10 In-Demand Skills\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Load the data\n",
    "job_skills = pd.read_csv(\"job_skills.csv\")\n",
    "skills = pd.read_csv(\"skills.csv\")\n",
    "\n",
    "# Merge on skill abbreviation\n",
    "merged_skills = job_skills.merge(skills, on='skill_abr', how='left')\n",
    "\n",
    "# Create a long string of all skill abbreviations\n",
    "skill_text = ' '.join(merged_skills['skill_abr'])\n",
    "\n",
    "# Generate the Word Cloud\n",
    "wordcloud = WordCloud(\n",
    "    width=800, \n",
    "    height=400, \n",
    "    background_color='white'\n",
    ").generate(skill_text)\n",
    "\n",
    "# Plot the Word Cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"Word Cloud of Skills\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CSVs\n",
    "job_skills = pd.read_csv(\"job_skills.csv\")\n",
    "skills = pd.read_csv(\"skills.csv\")\n",
    "postings = pd.read_csv(\"postings.csv\")\n",
    "\n",
    "# Extract state from location (assuming format: \"City, ST\")\n",
    "postings['state'] = postings['location'].str.extract(r',\\s*([A-Z]{2})$')\n",
    "\n",
    "# Merge postings with job_skills\n",
    "job_post_skills = postings[['job_id', 'state']].merge(job_skills, on='job_id', how='left')\n",
    "\n",
    "# Merge with skill names\n",
    "full_data = job_post_skills.merge(skills, on='skill_abr', how='left')\n",
    "\n",
    "# Count each skill by state\n",
    "skill_counts_by_state = full_data.groupby(['state', 'skill_abr']).size()\n",
    "\n",
    "# Get Top 10 skills per state\n",
    "top_skills_by_state = skill_counts_by_state.groupby(level=0).nlargest(10).reset_index(level=0, drop=True).reset_index(name='count')\n",
    "\n",
    "# ✅ Choose a specific state to plot\n",
    "state = 'NC'  \n",
    "\n",
    "# Filter top skills for selected state\n",
    "top_skills_in_state = top_skills_by_state[top_skills_by_state['state'] == state]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(top_skills_in_state['skill_abr'], top_skills_in_state['count'], color='cornflowerblue')\n",
    "plt.title(f\"Top 10 Skills in Demand in {state}\")\n",
    "plt.xlabel(\"Skills\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Load postings dataset\n",
    "postings = pd.read_csv(\"postings.csv\")\n",
    "\n",
    "# Drop rows with missing titles\n",
    "postings = postings.dropna(subset=[\"title\"])\n",
    "\n",
    "# Count top 10 job titles\n",
    "top_titles = postings['title'].value_counts().head(10)\n",
    "\n",
    "# Plot donut chart\n",
    "fig = px.pie(\n",
    "    names=top_titles.index,\n",
    "    values=top_titles.values,\n",
    "    title=\"Distribution of Top 10 Job Titles\",\n",
    "    hole=0.4  # makes it a donut chart\n",
    ")\n",
    "\n",
    "# Show chart\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "postings = pd.read_csv(\"postings.csv\")\n",
    "\n",
    "# Map 0 and 1 in 'remote_allowed' to labels\n",
    "postings['remote_allowed'] = postings['remote_allowed'].map({0.0: 'Non-Remote', 1.0: 'Remote'})\n",
    "\n",
    "# Group by work type and remote status, then calculate mean of median salary\n",
    "grouped_salaries = postings.groupby(['formatted_work_type', 'remote_allowed'])['med_salary'].mean().unstack()\n",
    "\n",
    "# Plot grouped bar chart\n",
    "grouped_salaries.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Average Median Salary by Work Type and Remote Allowance', fontsize=16)\n",
    "plt.xlabel('Work Type', fontsize=14)\n",
    "plt.ylabel('Average Median Salary', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Remote Allowed', bbox_to_anchor=(1.05, 1), loc='upper left')  # Legend outside\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataset\n",
    "postings = pd.read_csv(\"postings.csv\")\n",
    "\n",
    "# Extract state from location (assuming format like \"City, State\")\n",
    "postings['state'] = postings['location'].str.extract(r',\\s*(\\w+)$')\n",
    "\n",
    "# Group by state and calculate average median salary\n",
    "avg_salary_by_state = postings.groupby('state')['med_salary'].mean().sort_values(ascending=False).head(10)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "avg_salary_by_state.sort_values().plot(kind='barh', cmap='viridis')\n",
    "plt.title('Top 10 States with the Highest Average Salary')\n",
    "plt.xlabel('Average Salary')\n",
    "plt.ylabel('State')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.bar(\n",
    "    avg_salary_by_state.sort_values(),\n",
    "    x=avg_salary_by_state.sort_values(),\n",
    "    y=avg_salary_by_state.sort_values().index,\n",
    "    orientation='h',\n",
    "    color=avg_salary_by_state.sort_values(),\n",
    "    title=\"Top 10 States with the Highest Average Salary\",\n",
    "    labels={'x': 'Average Salary', 'y': 'State'}\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
